{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CD-AC/Master_AI/blob/main/muinar06_act1_individual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiDzBoKGwmMZ"
      },
      "source": [
        "# REDES NEURONALES\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de dígitos del 0 al 9 escritos a mano. Para ello, utilizaremos Keras con TensorFlow.\n",
        "\n",
        "El dataset a utilizar es MNIST, una base de datos constituida por (como no) imágenes de dígitos escritos a mano. Este dataset es ampliamente utilizado en docencia como punto de entrada al entrenamiento de redes neuronales y otros, pero también es muy utilizado en trabajos reales de investigación para el entrenamiento de imágenes. Puedes consultar más información sobre el dataset en [este enlace](https://es.wikipedia.org/wiki/Base_de_datos_MNIST).\n",
        "\n",
        "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados y que son perfectamente visibles en la versión PDF que debes entregar adjunta**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSHr268SwmMa"
      },
      "source": [
        "from keras.datasets.mnist import load_data\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zScMKU2OKSPD"
      },
      "source": [
        "Tenemos la suerte de que el dataset MNIST, el que vamos a utilizar en esta actividad, está guardado en Keras, por lo que podemos utilizarlo sin necesidad de buscar el dataset de forma externa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4voG2hxxG4h3"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JphLsCvgKrzb"
      },
      "source": [
        "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen los dígitos y sus etiquetas.\n",
        "\n",
        "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1muD4PHEG4h6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "eca54773-87de-44b7-a870-8761ce1cc931"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWGpJqVVLT3Y"
      },
      "source": [
        "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5a5PlswG4h8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "a55cf02d-d30b-4acb-be15-001bf812f498"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro\n",
        "#\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaqXlSMBwmMg"
      },
      "source": [
        "## 1. Información sobre el dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0aer8ZZwmMh"
      },
      "source": [
        "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-im9PnEwmMh"
      },
      "source": [
        "**Pregunta 1.1 *(0.25 puntos)*** ¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvP0Y4SCwmMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0172954a-ce55-48ac-9cb8-8ebb0a9f793b"
      },
      "source": [
        "### Tu código aquí ###\n",
        "print(\"Número de imágenes de entrenamiento:\", training_images.shape[0])\n",
        "print(\"Número de imágenes de test:\", test_images.shape[0])\n",
        "print(\"Tamaño de las imágenes:\", training_images.shape[1], \"x\", training_images.shape[2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de imágenes de entrenamiento: 60000\n",
            "Número de imágenes de test: 10000\n",
            "Tamaño de las imágenes: 28 x 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwp5ljFKwmMj"
      },
      "source": [
        "*Tu respuesta aquí*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2LsvfHOwmMk"
      },
      "source": [
        "**Pregunta 1.2 *(0.25 puntos)*** Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W5rzaGxwmMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cd0645c7-3ebf-4de4-9445-70396ac8fa8f"
      },
      "source": [
        "### Tu código aquí ###\n",
        "print(\"Tipo de dato de las imágenes de entrenamiento:\", training_images.dtype)\n",
        "print(\"Valores mínimos y máximos de píxeles:\", training_images.min(), training_images.max())\n",
        "print(\"Tipo de dato de las etiquetas de entrenamiento:\", training_labels.dtype)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dato de las imágenes de entrenamiento: uint8\n",
            "Valores mínimos y máximos de píxeles: 0 255\n",
            "Tipo de dato de las etiquetas de entrenamiento: uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaEWKFyvwmMm"
      },
      "source": [
        "*Tu respuesta aquí*\n",
        "\n",
        "Un ejemplo del dataset es una imagen en escala de grises de 28x28 píxeles que representa un dígito escrito a mano (del 0 al 9). Cada píxel contiene un valor de intensidad entre 0 y 255. La información en 'y' (las etiquetas) contiene el dígito correcto que representa cada imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Normalización y preprocesado de los datos"
      ],
      "metadata": {
        "id": "OXWLSFdnwAay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 2.1 (0.25 puntos)** Habreis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. ¿Cómo lo podemos hacer?"
      ],
      "metadata": {
        "id": "H9W9mgi7wUOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "n-BhUak6wjGc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 2.2 (0.25 puntos)** Utiliza la función ***reshape*** de Numpy para convertir las imágenes en vectores de características de un tamaño de (N, 784). Explica con tus palabras por qué es necesario hacer esto.\n",
        "\n"
      ],
      "metadata": {
        "id": "aAj9bKbJxDoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "training_images = training_images.reshape(60000, 784)\n",
        "test_images = test_images.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "qRdZBcCKxvLZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta a la pregunta 2.2**:\n",
        "\n",
        "Es necesario convertir las imágenes de 28x28 a un vector de 784 elementos porque las capas densas de una red neuronal esperan una entrada unidimensional."
      ],
      "metadata": {
        "id": "LCIZJRjWxwrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 2.3 (0.25 puntos)** Para facilitar el desarrollo de la actividad, vamos a expresar las etiquetas así:"
      ],
      "metadata": {
        "id": "VUJ9BpFSyR3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels = tf.keras.utils.to_categorical(training_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "jwgU9vScyZy_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra cómo son ahora los datos, como resultado de este cambio y también de los realizados en las dos preguntas anteriores. Debate cómo se beneficiará la red neuronal de todos estos cambios."
      ],
      "metadata": {
        "id": "itJBwG0Lyy2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "print(\"Dimensiones de las imágenes de entrenamiento después del preprocesamiento:\", training_images.shape)\n",
        "print(\"Dimensiones de las etiquetas de entrenamiento después del preprocesamiento:\", training_labels.shape)\n",
        "print(\"Primeras 5 etiquetas de entrenamiento después de to_categorical:\\n\", training_labels[0:5])"
      ],
      "metadata": {
        "id": "J0h1cc3CzJfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2f2f481f-6e79-4478-8d23-7dc4383a7ae6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de las imágenes de entrenamiento después del preprocesamiento: (60000, 784)\n",
            "Dimensiones de las etiquetas de entrenamiento después del preprocesamiento: (60000, 10)\n",
            "Primeras 5 etiquetas de entrenamiento después de to_categorical:\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respuesta a la pregunta 2.3:\n",
        "\n",
        "Ahora las imágenes son vectores normalizados entre 0 y 1, y las etiquetas están en formato one-hot encoding. La normalización ayuda a que el entrenamiento sea más estable y rápido. El one-hot encoding es necesario para la función de pérdida categorical_crossentropy utilizada en problemas de clasificación multiclase."
      ],
      "metadata": {
        "id": "GsG0MKk9zKsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creación del Modelo"
      ],
      "metadata": {
        "id": "dI3IAhOQ8zHi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYUWWsszMAKt"
      },
      "source": [
        "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
        "* **Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
        "* **Dense**: Añade una capa de neuronas\n",
        "* **Flatten**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
        "\n",
        "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
        "* **Relu** significa que \"Si X>0 devuelve X, si no, devuelve 0\", así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
        "* **Softmax** toma un conjunto de valores, y escoge el más grande."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBW1yE2MwPp"
      },
      "source": [
        " **Pregunta 3.1 (0.5 puntos)**. Utilizando Keras, y preparando los datos de X e Y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de MNIST con las siguientes características:\n",
        "\n",
        "* Una capa de entrada del tamaño adecuado.\n",
        "* Una capa oculta de 512 neuronas.\n",
        "* Una capa final con 10 salidas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTaD2QXIORwu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d2086af1-9255-4c88-ea92-e9a578792387"
      },
      "source": [
        "### Tu código para la red neuronal de la pregunta 3 aquí ###\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxr5hTKYOQnK"
      },
      "source": [
        "**Pregunta 3.2 (0.25 puntos)**: ¿crees conveniente utilizar una capa flatten en este caso? Motiva tu respuesta.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNjQEtUUG4iI"
      },
      "source": [
        "### Tu código para incluir una capa flatten si lo ves necesario ###"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta a la pregunta 3.2**:"
      ],
      "metadata": {
        "id": "D8vHUgfz0_ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 3.3 (0.25 puntos)**: Utiliza la función summary() para mostrar la estructura de tu modelo."
      ],
      "metadata": {
        "id": "QFVEWNBV1WnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YQpJ-DW61lOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "64b6a631-0df5-4c25-dd1b-a4c68fcfb812"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Compilación y entrenamiento"
      ],
      "metadata": {
        "id": "nco-l8vx1Kzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 4.1 (0.5 puntos)**: Compila tu modelo. Utiliza ***categorical_crossentropy*** como función de pérdida, ***Adam*** como optimizador, y monitoriza la ***tasa de acierto*** durante el entrenamiento. Explica qué hace cada cosa en la compilación."
      ],
      "metadata": {
        "id": "myZQUTCn1yD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "I_CPQN9p2a7J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta a la pregunta 4.1**:\n",
        "\n",
        "- Optimizer ('adam'): Es el algoritmo que ajusta los pesos de la red para minimizar la función de pérdida. Adam es un optimizador eficiente.\n",
        "\n",
        "- Loss ('categorical_crossentropy'): Es la función que mide qué tan bien se desempeña el modelo; calcula la diferencia entre la salida predicha y las etiquetas reales (en formato one-hot encoding). Se busca minimizar este valor.\n",
        "\n",
        "- Metrics (['accuracy']): Son las métricas que se monitorean durante el entrenamiento y la evaluación para entender el rendimiento del modelo. La precisión mide el porcentaje de predicciones correctas."
      ],
      "metadata": {
        "id": "TJ_vlOrj2dR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 4.2 (0.5 puntos)**: Utiliza la función ***fit()*** para entrenar tu modelo. Para ayudarte en tu primer entrenamiento, utiliza estos valores:\n",
        "*   epochs = 5\n",
        "*   batch_size = 32\n",
        "*   validation_split = 0.25\n",
        "\n"
      ],
      "metadata": {
        "id": "f7KSdoEr2rLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "history = model.fit(training_images, training_labels, epochs=5, batch_size=32, validation_split=0.25)"
      ],
      "metadata": {
        "id": "yytNVJf33WFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1006147e-9d02-4a81-cf25-ec9ec26025eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8891 - loss: 0.3757 - val_accuracy: 0.9634 - val_loss: 0.1217\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9716 - loss: 0.0958 - val_accuracy: 0.9670 - val_loss: 0.1080\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0543 - val_accuracy: 0.9739 - val_loss: 0.0859\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0392 - val_accuracy: 0.9690 - val_loss: 0.1045\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0285 - val_accuracy: 0.9685 - val_loss: 0.1168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiQ8qAzhRQ4L"
      },
      "source": [
        "# 5: Impacto al variar el número de neuronas en las capas ocultas\n",
        "\n",
        "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 512 y por otros valores. Para ello, utiliza la red neuronal de la pregunta 3, y su capa oculta cambia el número de neuronas:\n",
        "\n",
        "* **216 neuronas en la capa oculta\n",
        "* **1024 neuronas en la capa oculta\n",
        "\n",
        "y entrena la red en ambos casos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdP8ZwuaUV93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6d727e44-172f-4bff-9751-51ed78bb07b0"
      },
      "source": [
        "### Tu código para 216 neuronas aquí ###\n",
        "model_216 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(216, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_216.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_216 = model_216.fit(training_images, training_labels, epochs=5, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8723 - loss: 0.4438 - val_accuracy: 0.9525 - val_loss: 0.1601\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.1224 - val_accuracy: 0.9675 - val_loss: 0.1105\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0761 - val_accuracy: 0.9720 - val_loss: 0.0947\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 0.0465 - val_accuracy: 0.9743 - val_loss: 0.0854\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0352 - val_accuracy: 0.9735 - val_loss: 0.0943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXBlbbfuUaPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b9067c0b-82cd-4c7c-940c-cb811e303320"
      },
      "source": [
        "### Tu código para 1024 neuronas aquí ###\n",
        "model_1024 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(1024, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_1024.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_1024 = model_1024.fit(training_images, training_labels, epochs=5, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8923 - loss: 0.3566 - val_accuracy: 0.9645 - val_loss: 0.1182\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.9740 - loss: 0.0861 - val_accuracy: 0.9695 - val_loss: 0.0970\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.9856 - loss: 0.0479 - val_accuracy: 0.9731 - val_loss: 0.0902\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9897 - loss: 0.0318 - val_accuracy: 0.9742 - val_loss: 0.0877\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0226 - val_accuracy: 0.9755 - val_loss: 0.0946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG0h2HL-Uj93"
      },
      "source": [
        "**Pregunta 5.1 (0.5 puntos)**: ¿Cual es el impacto que tiene la red neuronal?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respuesta a la pregunta 5.1:\n",
        "\n",
        "Variar el número de neuronas en las capas ocultas afecta la capacidad del modelo para aprender patrones complejos. Un mayor número de neuronas generalmente permite aprender patrones más intrincados, pero también aumenta el riesgo de sobreajuste (overfitting) si no hay suficiente datos o regularización. Un número menor de neuronas puede limitar la capacidad del modelo para capturar la complejidad de los datos."
      ],
      "metadata": {
        "id": "0ff9PdKi7wgq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37cIr81ZYJj"
      },
      "source": [
        "# 6: Número de neuronas de la capa de salida\n",
        "Considerad la capa final, la de salida de la red neuronal de la pregunta 3.\n",
        "\n",
        "**Pregunta 6.1 (0.25 puntos)**: ¿Por qué son 10 las neuronas de la última capa?\n",
        "\n",
        "**Pregunta 6.2 (0.25 puntos)**: ¿Qué pasaría si tuvieras una cantidad diferente a 10?\n",
        "\n",
        "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhbZkppYZOCS"
      },
      "source": [
        "### Tu código de la red neuronal con 5 neuronas en la capa de salida de la pregunta 7 aquí ###\n",
        "model_5_output = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(5, activation='softmax') # Cambiado a 5 neuronas\n",
        "])\n",
        "model_5_output.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Intentar entrenar esto probablemente dará un error o resultados sin sentido\n",
        "# history_5_output = model_5_output.fit(training_images, training_labels, epochs=5, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLsQcq-6aUoD"
      },
      "source": [
        "Tu respuestas a la pregunta 6.1 aquí:\n",
        "\n",
        "Son 10 neuronas en la última capa porque hay 10 clases posibles para clasificar (los dígitos del 0 al 9). Cada neurona de salida corresponde a una de estas clases, y la activación softmax nos da la probabilidad de que la imagen pertenezca a cada clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1f_7ZFeaUu6"
      },
      "source": [
        "Tu respuestas a la pregunta 6.2 aquí:\n",
        "\n",
        "Si tuvieras una cantidad diferente a 10 neuronas en la capa de salida, el modelo no podría clasificar correctamente en las 10 categorías posibles. Si son menos de 10, no podría representar todas las clases. Si son más, sería ineficiente y probablemente incorrecto para este problema específico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIBCkshaf2y"
      },
      "source": [
        "# 7: Aumento de epoch y su efecto en la red neuronal\n",
        "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 3:\n",
        "\n",
        "**Pregunta 7.1 (0.25 puntos)**\n",
        "* Intentad 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5.\n",
        "\n",
        "**Pregunta 7.2 (0.25 puntos)**\n",
        "* Intenta ahora con 30 epoch para su entrenamiento.\n",
        "\n",
        "**Pregunta 7.3 (0.25 puntos)**\n",
        "* ¿Qué está pasando en la pregunta anterior? Explica tu respuesta y da el nombre de este efecto si lo conoces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5vk_imG4iZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4fa45731-001d-401d-c807-a82b45862e1b"
      },
      "source": [
        "### Tu código para 15 epoch aquí ###\n",
        "model_15_epochs = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_15_epochs.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_15 = model_15_epochs.fit(training_images, training_labels, epochs=15, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8875 - loss: 0.3842 - val_accuracy: 0.9553 - val_loss: 0.1478\n",
            "Epoch 2/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0976 - val_accuracy: 0.9704 - val_loss: 0.0994\n",
            "Epoch 3/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.0584 - val_accuracy: 0.9724 - val_loss: 0.0958\n",
            "Epoch 4/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0364 - val_accuracy: 0.9738 - val_loss: 0.0891\n",
            "Epoch 5/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0275 - val_accuracy: 0.9729 - val_loss: 0.1002\n",
            "Epoch 6/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0197 - val_accuracy: 0.9685 - val_loss: 0.1150\n",
            "Epoch 7/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0176 - val_accuracy: 0.9744 - val_loss: 0.0995\n",
            "Epoch 8/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9771 - val_loss: 0.0903\n",
            "Epoch 9/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.9727 - val_loss: 0.1129\n",
            "Epoch 10/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0114 - val_accuracy: 0.9752 - val_loss: 0.1062\n",
            "Epoch 11/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0106 - val_accuracy: 0.9769 - val_loss: 0.1100\n",
            "Epoch 12/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9776 - val_loss: 0.1106\n",
            "Epoch 13/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9738 - val_loss: 0.1296\n",
            "Epoch 14/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9783 - val_loss: 0.1143\n",
            "Epoch 15/15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9773 - val_loss: 0.1297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9jQ26Gda5cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a203004d-ce4f-4597-cfcb-fe4140cc4e7c"
      },
      "source": [
        "### Tu código para 30 epoch aquí ###\n",
        "model_30_epochs = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_30_epochs.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_30 = model_30_epochs.fit(training_images, training_labels, epochs=30, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.8829 - loss: 0.3875 - val_accuracy: 0.9582 - val_loss: 0.1347\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.1004 - val_accuracy: 0.9695 - val_loss: 0.0991\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0526 - val_accuracy: 0.9745 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0372 - val_accuracy: 0.9709 - val_loss: 0.0952\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0279 - val_accuracy: 0.9723 - val_loss: 0.0949\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0212 - val_accuracy: 0.9769 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0152 - val_accuracy: 0.9728 - val_loss: 0.1044\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0146 - val_accuracy: 0.9767 - val_loss: 0.0970\n",
            "Epoch 9/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9750 - val_loss: 0.1039\n",
            "Epoch 10/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0115 - val_accuracy: 0.9747 - val_loss: 0.1110\n",
            "Epoch 11/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0084 - val_accuracy: 0.9768 - val_loss: 0.1007\n",
            "Epoch 12/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0063 - val_accuracy: 0.9771 - val_loss: 0.1067\n",
            "Epoch 13/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.9783 - val_loss: 0.1036\n",
            "Epoch 14/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9768 - val_loss: 0.1218\n",
            "Epoch 15/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9780 - val_loss: 0.1227\n",
            "Epoch 16/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9781 - val_loss: 0.1204\n",
            "Epoch 17/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9742 - val_loss: 0.1504\n",
            "Epoch 18/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 0.9796 - val_loss: 0.1177\n",
            "Epoch 19/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9796 - val_loss: 0.1196\n",
            "Epoch 20/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9767 - val_loss: 0.1381\n",
            "Epoch 21/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.9769 - val_loss: 0.1338\n",
            "Epoch 22/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9759 - val_loss: 0.1565\n",
            "Epoch 23/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0053 - val_accuracy: 0.9781 - val_loss: 0.1410\n",
            "Epoch 24/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9794 - val_loss: 0.1349\n",
            "Epoch 25/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9783 - val_loss: 0.1380\n",
            "Epoch 26/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9753 - val_loss: 0.1759\n",
            "Epoch 27/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0068 - val_accuracy: 0.9781 - val_loss: 0.1595\n",
            "Epoch 28/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9772 - val_loss: 0.1552\n",
            "Epoch 29/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9793 - val_loss: 0.1422\n",
            "Epoch 30/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9761 - val_loss: 0.1718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs0fjzH4bmSR"
      },
      "source": [
        "Tu respuesta a la pregunta 7.3 aquí:\n",
        "\n",
        "Al aumentar mucho las epochs, la pérdida en los datos de entrenamiento puede seguir disminuyendo, pero la pérdida en los datos de validación puede dejar de disminuir o incluso aumentar. Esto significa que el modelo está aprendiendo los datos de entrenamiento de forma demasiado específica, incluyendo el ruido, y no generaliza bien a datos nuevos. Este efecto se llama sobreajuste (overfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlIgNG4Yb_N6"
      },
      "source": [
        "# 8: Early stop\n",
        "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
        "\n",
        "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (loss) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5UwceFUG4ic"
      },
      "source": [
        "### Ejemplo de código\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')> 0.85):\n",
        "              print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
        "              self.model.stop_training = True"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bjd8wGKccrn"
      },
      "source": [
        "**Pregunta 8.1. *(0.75 puntos)***: Consulta la documentación de Keras y aprende cómo podemos utilizar Early stop en nuestro modelos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Tu código aquí ###\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model_early_stop = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_early_stop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_early_stop = model_early_stop.fit(training_images, training_labels, epochs=30, batch_size=32, validation_split=0.25, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "3P3sQQky8qI6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bd3d4ad4-1cc4-48a2-ab22-78b38d28662b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8866 - loss: 0.3841 - val_accuracy: 0.9585 - val_loss: 0.1387\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.0956 - val_accuracy: 0.9689 - val_loss: 0.1014\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0560 - val_accuracy: 0.9687 - val_loss: 0.1032\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0365 - val_accuracy: 0.9722 - val_loss: 0.0963\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0247 - val_accuracy: 0.9734 - val_loss: 0.0993\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0214 - val_accuracy: 0.9741 - val_loss: 0.0964\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.9765 - val_loss: 0.0892\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.9769 - val_loss: 0.0939\n",
            "Epoch 9/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9701 - val_loss: 0.1258\n",
            "Epoch 10/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9756 - val_loss: 0.1111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_yZ9B8gTFqR"
      },
      "source": [
        "## 9. Unidades de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuVNxmXSTFqR"
      },
      "source": [
        "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras unidades como ReLU.\n",
        "\n",
        "**Pregunta 9.1 *(0.75 puntos)***: Utilizando la red realizada en el ejercicio 3, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
        "\n",
        "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoYUajTuTFqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ffc91fe8-4857-489c-e2cc-42aec974282e"
      },
      "source": [
        "## Tu código y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto\n",
        "\n",
        "# Ejemplo con Sigmoid\n",
        "model_sigmoid = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='sigmoid', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Entrenando con Sigmoid:\")\n",
        "history_sigmoid = model_sigmoid.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)\n",
        "\n",
        "# Ejemplo con ReLU\n",
        "model_relu = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Entrenando con ReLU:\")\n",
        "history_relu = model_relu.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando con Sigmoid:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.5698 - val_accuracy: 0.9299 - val_loss: 0.2425\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2126 - val_accuracy: 0.9511 - val_loss: 0.1749\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1460 - val_accuracy: 0.9590 - val_loss: 0.1389\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0996 - val_accuracy: 0.9641 - val_loss: 0.1192\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0720 - val_accuracy: 0.9703 - val_loss: 0.0964\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0546 - val_accuracy: 0.9707 - val_loss: 0.0949\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0407 - val_accuracy: 0.9736 - val_loss: 0.0895\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0305 - val_accuracy: 0.9741 - val_loss: 0.0864\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0234 - val_accuracy: 0.9753 - val_loss: 0.0864\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0162 - val_accuracy: 0.9707 - val_loss: 0.1010\n",
            "\n",
            "\n",
            "Entrenando con ReLU:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.3783 - val_accuracy: 0.9623 - val_loss: 0.1284\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0916 - val_accuracy: 0.9669 - val_loss: 0.1119\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0537 - val_accuracy: 0.9703 - val_loss: 0.0985\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0399 - val_accuracy: 0.9753 - val_loss: 0.0794\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0256 - val_accuracy: 0.9767 - val_loss: 0.0802\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.9755 - val_loss: 0.0939\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0181 - val_accuracy: 0.9751 - val_loss: 0.0965\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.9753 - val_loss: 0.0990\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0094 - val_accuracy: 0.9773 - val_loss: 0.0963\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9773 - val_loss: 0.1009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Velocidad de convergencia: ReLU tiende a entrenar más rápido que Sigmoid debido al problema del gradiente desvanecido (vanishing gradient) en Sigmoid para valores de entrada muy grandes o muy pequeños.\n",
        "\n",
        "- Métricas obtenidas: Compara la precisión y pérdida alcanzada por ambos modelos. ReLU suele obtener mejores resultados en tareas de clasificación de imágenes.\n",
        "\n",
        "- Por qué las diferencias: La función ReLU introduce no linealidad sin saturarse para entradas positivas, lo que ayuda a que los gradientes fluyan mejor durante el entrenamiento."
      ],
      "metadata": {
        "id": "YtJTpshuPuqT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu6RbUFKTFqT"
      },
      "source": [
        "## 10. Inicialización de parámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abmm05UPTFqU"
      },
      "source": [
        "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
        "\n",
        "**Pregunta 10.1 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
        "\n",
        "* Inicialización con ceros.\n",
        "* Inicialización con una variable aleatoria normal.\n",
        "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcMt7pSkTFqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1474a28f-7c3c-42bc-b896-affed3e1efb9"
      },
      "source": [
        "## Tu código y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto\n",
        "\n",
        "import tensorflow as tf # Asegúrate de tener tensorflow importado\n",
        "\n",
        "# Ejemplo con Inicialización con ceros\n",
        "print(\"Entrenando con Inicialización con ceros:\")\n",
        "model_zeros = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,),\n",
        "                        kernel_initializer='zeros'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_zeros.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_zeros = model_zeros.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)\n",
        "\n",
        "\n",
        "# Ejemplo con Inicialización aleatoria normal\n",
        "print(\"Entrenando con Inicialización aleatoria normal:\")\n",
        "model_random_normal = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,),\n",
        "                        kernel_initializer='random_normal'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_random_normal.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_random_normal = model_random_normal.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)\n",
        "\n",
        "\n",
        "# Ejemplo con Glorot uniform (por defecto en Dense)\n",
        "print(\"Entrenando con Glorot uniform:\")\n",
        "model_glorot_uniform = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,),\n",
        "                        kernel_initializer='glorot_uniform'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_glorot_uniform.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_glorot_uniform = model_glorot_uniform.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando con Inicialización con ceros:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1117 - loss: 2.3018 - val_accuracy: 0.1076 - val_loss: 2.3021\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1128 - loss: 2.3013 - val_accuracy: 0.1076 - val_loss: 2.3021\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1144 - loss: 2.3010 - val_accuracy: 0.1076 - val_loss: 2.3019\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1153 - loss: 2.3007 - val_accuracy: 0.1076 - val_loss: 2.3017\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1131 - loss: 2.3012 - val_accuracy: 0.1076 - val_loss: 2.3019\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1138 - loss: 2.3012 - val_accuracy: 0.1076 - val_loss: 2.3019\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1132 - loss: 2.3010 - val_accuracy: 0.1076 - val_loss: 2.3019\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1148 - loss: 2.3009 - val_accuracy: 0.1076 - val_loss: 2.3019\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1135 - loss: 2.3014 - val_accuracy: 0.1076 - val_loss: 2.3020\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1126 - loss: 2.3015 - val_accuracy: 0.1076 - val_loss: 2.3018\n",
            "\n",
            "\n",
            "Entrenando con Inicialización aleatoria normal:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.3751 - val_accuracy: 0.9591 - val_loss: 0.1359\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0963 - val_accuracy: 0.9689 - val_loss: 0.1009\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0560 - val_accuracy: 0.9715 - val_loss: 0.0940\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0383 - val_accuracy: 0.9685 - val_loss: 0.1071\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0254 - val_accuracy: 0.9775 - val_loss: 0.0807\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0182 - val_accuracy: 0.9760 - val_loss: 0.0925\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0174 - val_accuracy: 0.9785 - val_loss: 0.0900\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0136 - val_accuracy: 0.9756 - val_loss: 0.0951\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0114 - val_accuracy: 0.9758 - val_loss: 0.1057\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.9739 - val_loss: 0.1268\n",
            "\n",
            "\n",
            "Entrenando con Glorot uniform:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.3946 - val_accuracy: 0.9624 - val_loss: 0.1284\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0947 - val_accuracy: 0.9678 - val_loss: 0.1041\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0556 - val_accuracy: 0.9686 - val_loss: 0.0981\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0380 - val_accuracy: 0.9758 - val_loss: 0.0862\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0271 - val_accuracy: 0.9743 - val_loss: 0.0900\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0196 - val_accuracy: 0.9752 - val_loss: 0.0894\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.9729 - val_loss: 0.1047\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0152 - val_accuracy: 0.9797 - val_loss: 0.0861\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9764 - val_loss: 0.1025\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0094 - val_accuracy: 0.9766 - val_loss: 0.1054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inicialización con ceros: Generalmente lleva a que todas las neuronas en una capa aprendan los mismos patrones, lo que limita la capacidad del modelo.\n",
        "\n",
        "- Inicialización aleatoria normal/uniforme: Permite que las neuronas aprendan diferentes características. Las estrategias como Glorot (Xavier) y He son diseñadas para mantener la varianza de las activaciones y gradientes a través de las capas, lo que ayuda a un entrenamiento más efectivo, especialmente en redes profundas.\n",
        "\n",
        "- Diferencias: Compara la velocidad de convergencia y el rendimiento final (precisión/pérdida) con las diferentes inicializaciones. Glorot uniform debería funcionar mejor que las inicializaciones ingenuas como ceros o aleatoria simple."
      ],
      "metadata": {
        "id": "VaitSXlAP8fU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqIAyVWrTFqV"
      },
      "source": [
        "## 11. Optimizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcYj29hYTFqW"
      },
      "source": [
        "**Problema 11.1 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fWDiqXvTFqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0227464c-bbc2-4557-f410-aef13506654f"
      },
      "source": [
        "## Tu código y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## No olvides utilizar celdas de Markdown para texto\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Ejemplo con SGD\n",
        "print(\"Entrenando con SGD:\")\n",
        "model_sgd = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_sgd.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_sgd = model_sgd.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)\n",
        "\n",
        "# Ejemplo con RMSprop\n",
        "print(\"Entrenando con RMSprop:\")\n",
        "model_rmsprop = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_rmsprop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_rmsprop = model_rmsprop.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)\n",
        "\n",
        "\n",
        "# Ejemplo con Ada\n",
        "print(\"Entrenando con Adam:\")\n",
        "model_adam_opt = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_adam_opt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_adam_opt = model_adam_opt.fit(training_images, training_labels, epochs=10, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando con SGD:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7493 - loss: 1.0627 - val_accuracy: 0.9003 - val_loss: 0.3800\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.3716 - val_accuracy: 0.9119 - val_loss: 0.3130\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.3062 - val_accuracy: 0.9229 - val_loss: 0.2809\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2708 - val_accuracy: 0.9291 - val_loss: 0.2549\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.2497 - val_accuracy: 0.9337 - val_loss: 0.2379\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.2309 - val_accuracy: 0.9391 - val_loss: 0.2245\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9410 - loss: 0.2109 - val_accuracy: 0.9425 - val_loss: 0.2104\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.1977 - val_accuracy: 0.9453 - val_loss: 0.1991\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1870 - val_accuracy: 0.9481 - val_loss: 0.1901\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1794 - val_accuracy: 0.9512 - val_loss: 0.1809\n",
            "\n",
            "\n",
            "Entrenando con RMSprop:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3704 - val_accuracy: 0.9565 - val_loss: 0.1539\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0998 - val_accuracy: 0.9683 - val_loss: 0.1088\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0615 - val_accuracy: 0.9741 - val_loss: 0.0959\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0458 - val_accuracy: 0.9733 - val_loss: 0.1031\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0323 - val_accuracy: 0.9750 - val_loss: 0.0998\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0232 - val_accuracy: 0.9744 - val_loss: 0.1056\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0168 - val_accuracy: 0.9765 - val_loss: 0.1069\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0137 - val_accuracy: 0.9781 - val_loss: 0.1037\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0095 - val_accuracy: 0.9769 - val_loss: 0.1079\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9791 - val_loss: 0.1002\n",
            "\n",
            "\n",
            "Entrenando con Adam:\n",
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.3845 - val_accuracy: 0.9615 - val_loss: 0.1329\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.0927 - val_accuracy: 0.9667 - val_loss: 0.1063\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0579 - val_accuracy: 0.9720 - val_loss: 0.0915\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0369 - val_accuracy: 0.9749 - val_loss: 0.0869\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0246 - val_accuracy: 0.9736 - val_loss: 0.0904\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0191 - val_accuracy: 0.9757 - val_loss: 0.0957\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0149 - val_accuracy: 0.9737 - val_loss: 0.1008\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.9770 - val_loss: 0.0945\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9753 - val_loss: 0.1018\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.9750 - val_loss: 0.1138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SGD: Es un optimizador básico que puede ser lento para converger pero a veces alcanza mejores mínimos locales.\n",
        "\n",
        "- Optimizadores adaptativos (Adam, RMSprop, etc.): Tienden a converger más rápido y a menudo logran mejores resultados al adaptar la tasa de aprendizaje para cada parámetro.\n",
        "\n",
        "- Diferencias: Compara la velocidad de entrenamiento y el rendimiento final. Adam y RMSprop suelen ser más eficientes para este tipo de problema."
      ],
      "metadata": {
        "id": "2Ajh7fMcQJPC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkfTFoJOTFqZ"
      },
      "source": [
        "## 12. Regularización y red final *(1.25 puntos)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6CQhK7ZTFqZ"
      },
      "source": [
        "**Problema 12.1 *(2 puntos)***: Entrenar una red final que sea capaz de obtener una accuracy en el validation superior al 95%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
        "\n",
        "* Número de capas y neuronas por capa\n",
        "* Optimizadores y sus parámetros\n",
        "* Batch size\n",
        "* Unidades de activación\n",
        "* Uso de capas dropout, regularización L2, regularización L1...\n",
        "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
        "* Batch normalization\n",
        "\n",
        "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
        "\n",
        "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUJ5AtunTFqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1321
        },
        "outputId": "04d26d38-1ab0-48a1-adf2-0c64a7f7eb4e"
      },
      "source": [
        "## Tu modelo y comentarios de texto aquí\n",
        "## Puedes incluir tantas celdas como quieras\n",
        "## pero recuerda visualizar la gráfica con la tasa de acierto\n",
        "## así como utilizar la función predict() para tu última evaluación\n",
        "## (deberás consultar la documentación de Keras para entender la función)\n",
        "## No olvides utilizar celdas de Markdown para texto\n",
        "\n",
        "model_final = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_final.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "early_stopping_final = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "print(\"Entrenando modelo final:\")\n",
        "history_final = model_final.fit(training_images, training_labels, epochs=50, batch_size=64, validation_split=0.25, callbacks=[early_stopping_final])\n",
        "\n",
        "# Evaluar el modelo final en los datos de test\n",
        "loss, accuracy = model_final.evaluate(test_images, test_labels)\n",
        "print(\"Accuracy en datos de test:\", accuracy)\n",
        "\n",
        "# Visualizar la gráfica de accuracy y loss durante el entrenamiento\n",
        "plt.plot(history_final.history['accuracy'], label='accuracy')\n",
        "plt.plot(history_final.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.9, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_final.history['loss'], label='loss')\n",
        "plt.plot(history_final.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando modelo final:\n",
            "Epoch 1/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.4631 - val_accuracy: 0.9595 - val_loss: 0.1335\n",
            "Epoch 2/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1267 - val_accuracy: 0.9699 - val_loss: 0.0970\n",
            "Epoch 3/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.0807 - val_accuracy: 0.9739 - val_loss: 0.0905\n",
            "Epoch 4/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0631 - val_accuracy: 0.9719 - val_loss: 0.0936\n",
            "Epoch 5/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0482 - val_accuracy: 0.9747 - val_loss: 0.0862\n",
            "Epoch 6/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0436 - val_accuracy: 0.9754 - val_loss: 0.0850\n",
            "Epoch 7/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0378 - val_accuracy: 0.9742 - val_loss: 0.0988\n",
            "Epoch 8/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0348 - val_accuracy: 0.9765 - val_loss: 0.0949\n",
            "Epoch 9/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0306 - val_accuracy: 0.9722 - val_loss: 0.1129\n",
            "Epoch 10/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0310 - val_accuracy: 0.9754 - val_loss: 0.0971\n",
            "Epoch 11/50\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0253 - val_accuracy: 0.9775 - val_loss: 0.0911\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0858\n",
            "Accuracy en datos de test: 0.9800000190734863\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Arquitectura del Modelo: Experimentar con el número de capas densas y la cantidad de neuronas en cada capa. Aumentar la complejidad del modelo (más capas o neuronas) le permite aprender patrones más intrincados, pero también incrementa el riesgo de sobreajuste si no se aplican técnicas de regularización adecuadas.\n",
        "\n",
        "- Optimización y Hiperparámetros: Seleccionar un optimizador eficaz (como Adam o RMSprop, que suelen funcionar bien en este tipo de problemas) y ajustar sus parámetros si es necesario. El tamaño del batch también influye en la estabilidad y velocidad del entrenamiento.\n",
        "\n",
        "- Unidades de Activación: Mantener el uso de unidades de activación que han demostrado ser efectivas (como ReLU en las capas ocultas) para asegurar un flujo de gradientes adecuado durante el entrenamiento.\n",
        "\n",
        "- Técnicas de Regularización: Este es un aspecto crucial para evitar el sobreajuste. Implementar técnicas como:\n",
        "\n",
        "1.  Dropout: Desactivar aleatoriamente un porcentaje de neuronas durante el entrenamiento para evitar que la red dependa demasiado de neuronas específicas.\n",
        "\n",
        "2. Regularización L1 o L2: Añadir una penalización a la función de pérdida basada en el tamaño de los pesos del modelo, lo que tiende a mantener los pesos pequeños.\n",
        "\n",
        "3. Batch Normalization: Normalizar las activaciones de las capas para estabilizar el entrenamiento y permitir el uso de tasas de aprendizaje más altas.\n",
        "\n",
        "- Early Stopping: Utilizar esta técnica como un callback durante el entrenamiento. Permite monitorear una métrica en el conjunto de validación (como la pérdida de validación o la precisión de validación) y detener el entrenamiento automáticamente cuando esa métrica deja de mejorar. Esto previene el sobreajuste y ahorra tiempo de cómputo al no entrenar más de lo necesario."
      ],
      "metadata": {
        "id": "r5HgjtyXQeJf"
      }
    }
  ]
}